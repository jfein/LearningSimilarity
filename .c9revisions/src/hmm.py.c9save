{"ts":1354038371762,"silentsave":true,"restoring":false,"patch":[[{"diffs":[[1,"from util import SourceArticles, cosine, PORTER_STEMMER\n\nclass HMM():\n\n    def __init__(self, ngram):\n        self.ngram = ngram\n\n        # Set up the source articles\n        self.src_articles = SourceArticles(\n            stdizer=PORTER_STEMMER,\n            omit_stopwords=True,\n            stdize_kws=True,\n            stdize_article=True,\n            max_phrase_size=ngram\n        )\n        \n        self.spin_groups = [frozenset()]  # List of spin groups (spin group is a set of phrase tuples), indexed by spin group ID\n        self.transitions = {}  # Mapping rom spin group ID to dict of spgid to counts\n        \n        spin_groups_inverse = {frozenset():0}  # Mapping from spin group to spin group ID\n        \n        for article_num in range(500):\n            sentences = self.src_articles.get_article_sentences(article_num)\n\n            for sentence in sentences:                    \n                prev_spgid = None\n            \n                for spin_group in sentence:\n                    # Get ID for this spin group\n                    if spin_group not in spin_groups_inverse:\n                        self.spin_groups.append(spin_group)\n                        sgid = len(self.spin_groups) - 1\n                        spin_groups_inverse[spin_group] = sgid\n                    sgid = spin_groups_inverse[spin_group]\n                    \n                    # Add the edge from prev_spgid to spgid\n                    transition_from_prev = self.transitions.get(prev_spgid, {})\n                    transition_from_prev_to_cur = transition_from_prev.get(sgid, 0)\n                    transition_from_prev_to_cur += 1\n                    transition_from_prev[sgid] = transition_from_prev_to_cur\n                    self.transitions[prev_spgid] = transition_from_prev\n                    \n                    prev_spgid = sgid\n                    \n    def transition_prob(self, src_sgid, dest_sgid):\n        '''\n        Returns probability that src_sgid will transition to dest_sgid\n        '''\n        if src_sgid == 0 or dest_sgid == 0:\n            return 1.0 / len(self.spin_groups)\n        \n        edges_from_src = self.transitions.get(src_sgid, {})\n        if dest_sgid not in edges_from_src:\n            return 0.0\n        return float(edges_from_src[dest_sgid]) / sum(edges_from_src.values())\n        \n    def emission_prob(self, sgid, phrase):\n        '''\n        Returns probability that sgid will emit phrase. Phrase is a list of strings.\n        '''\n        if sgid == 0:\n            return 1.0\n            \n        spin_group = self.spin_groups[sgid]\n        if phrase in spin_group:\n            return 1.0 / len(spin_group)\n        else:\n            return 0.0\n            \n    def classify_sentence(self, sentence):\n        '''\n        Returns the most likely sequence of spin groups that could have generated sentence\n        n is the number of n-grams to consider\n        '''\n        deltas = []\n        \n        for t in range(len(sentence)):\n            delta = {}\n            for sgid in range(len(self.spin_groups)):\n                for wb in range(self.ngram):\n                    key = (sgid, wb)\n                    \n                    # Make sure theres enough words back\n                    if t-wb < 0:\n                        delta[key] = (0.0, (None, 0))\n                        continue\n                    \n                    # Extract the phrase\n                    phrase = sentence[t-wb:t+1]\n                                        \n                    # Is a start probability\n                    if t-1-wb < 0:\n                        value = self.transition_prob(None, sgid) * self.emission_prob(sgid, phrase)\n                        delta[key] = (value , (None, 0))\n                    # Not a start probability\n                    else:\n                        prev_delta = deltas[t-1-wb]\n                        best_prev_key = None\n                        max = 0.0\n                        emit_prob = self.emission_prob(sgid, phrase)\n                        if (emit_prob > 0.0):\n                            for (prev_sgid, prev_wb), (prev_prob, prev_key) in prev_delta.iteritems():\n                                value = prev_prob * self.transition_prob(prev_sgid, sgid) * emit_prob\n                                if value > max:\n                                    max = value\n                                    best_prev_key = (prev_sgid, prev_wb)\n                        if best_prev_key:\n                            delta[key] = (max , best_prev_key)\n                            \n            deltas.append(delta)\n                    \n        # Find the max in the last delta\n        last_delta = deltas[t]\n        max_prob = 0.0\n        best_kv = None\n        for (sgid, wb) , (prob, (prev_sgid, prev_wb)) in last_delta.iteritems():\n            if prob >= max_prob:\n                max_prob = prob\n                best_kv = (sgid, wb) , (prob, (prev_sgid, prev_wb))\n   \n        # Backtrack \n        spin_groups = []\n        t = len(sentence)-1\n        while t >= 0:\n            (sgid, wb) , (prob, (prev_sgid, prev_wb)) = best_kv\n            spin_groups.append(sgid)\n            t = t - wb - 1\n            best_kv = (prev_sgid, prev_wb) , deltas[t].get((prev_sgid, prev_wb), (0.0, (None, 0)))\n                 \n        # Returns the spin groups found\n        spin_groups.reverse()\n        return spin_groups\n        \n            \n\n        \nif __name__ == \"__main__\":\n    hmm = HMM(4)\n    \n    for sgid, spin_group in enumerate(hmm.spin_groups):\n        print \"{0} : {1}\".format(sgid, spin_group)\n        \n    print \"--------------------------------------------------------------------\"\n    print \"--------------------------------------------------------------------\"\n\n    \n    sentence = tuple(hmm.src_articles.spin_article(200)[0].split())\n    \n    print len(sentence)\n    print \"CLASSIFYING :\\n{0}\".format(sentence)\n    \n    groups = hmm.classify_sentence(sentence)\n    \n    for group in groups:\n        print hmm.spin_groups[group]\n        \n    print \"--------------------------------------------------------------------\" \n \n    sentence = tuple(hmm.src_articles.spin_article(200)[0].split())\n    \n    print len(sentence)\n    print \"CLASSIFYING :\\n{0}\".format(sentence)\n    \n    groups = hmm.classify_sentence(sentence)\n    \n    for group in groups:\n        print hmm.spin_groups[group]\n        "]],"start1":0,"start2":0,"length1":0,"length2":6364}]],"length":6364}
